{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c6382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer , LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "from rake_nltk import Rake\n",
    "import yake\n",
    "import contractions\n",
    "from unidecode import unidecode\n",
    "from string import punctuation\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from autocorrect import Speller\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from sklearn.metrics import recall_score,precision_score,accuracy_score,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f343817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('Restaurant_Reviews.tsv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e5d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect language\n",
    "\n",
    "def lang_detect(data):\n",
    "    lang = detect(data)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8c7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['Review'].apply(lang_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87f4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate\n",
    "\n",
    "def translator(data):\n",
    "    trans = Translator()\n",
    "    t = trans.translate(data)\n",
    "    return t.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204ce387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(df['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6109bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated_text'] = df['Review'].apply(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfaf460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b648937",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = stopwords.words('english')\n",
    "stop_list.remove('no')\n",
    "stop_list.remove('nor')\n",
    "stop_list.remove('not')\n",
    "def clean_data(data):\n",
    "    accent = unidecode(data)\n",
    "    expand_data = contractions.fix(data)\n",
    "    clean_text = [word.lower() for word in word_tokenize(expand_data) if (word not in punctuation) \n",
    "                  and (word not in stop_list) and (word.isalpha() and (len(word)>2))] \n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af889da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(df['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fa14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_data'] = df['Review'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(df['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ngrams\n",
    "\n",
    "def n_grams(data,n_grams):\n",
    "    grams = ngrams(data,n_grams) \n",
    "    gram_list = []\n",
    "    for gram in grams:\n",
    "        gram_list.append(' '.join(gram))\n",
    "    return gram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams(df['clean_data'][0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = df['clean_data'].apply(lambda x : n_grams(x,1))\n",
    "unigram_list = []\n",
    "for uni in unigram :\n",
    "    unigram_list.extend(uni)\n",
    "cnt = Counter(unigram_list).most_common(100)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigram\n",
    "\n",
    "bigram = df['clean_data'].apply(lambda x : n_grams(x,2))\n",
    "bigram\n",
    "bigram_list = []\n",
    "for bi in bigram :\n",
    "    bigram_list.extend(bi)\n",
    "cnt = Counter(bigram_list).most_common(100)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73702f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trigram\n",
    "\n",
    "trigram = df['clean_data'].apply(lambda x : n_grams(x,3))\n",
    "trigram_list = []\n",
    "for tri in trigram :\n",
    "    trigram_list.extend(tri)\n",
    "cnt = Counter(trigram_list).most_common(25)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadragram = df['clean_data'].apply(lambda x : n_grams(x,4))\n",
    "quadragram_list = []\n",
    "\n",
    "for quadra in quadragram:\n",
    "    quadragram_list.extend(quadra)\n",
    "cnt = Counter(quadragram_list).most_common(25)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5e7b7",
   "metadata": {},
   "source": [
    "## WORD CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2253b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(data,column):\n",
    "    string = ' '.join(data[column])+' '\n",
    "    cloud = WordCloud(width = 800,height = 800,background_color = 'white',min_font_size = 10).generate(string)\n",
    "    plt.figure(figsize = (8,8),facecolor = None)\n",
    "    plt.imshow(cloud)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ' '.join(df['Review'])+' '\n",
    "cloud = WordCloud(background_color = 'white').generate(string)\n",
    "plt.figure(figsize = (8,8),facecolor = None)\n",
    "plt.imshow(cloud)\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c004f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(df,'Review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694d0e9",
   "metadata": {},
   "source": [
    "## Yake Key phrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_extractor(data):\n",
    "    keyword_extractor = yake.KeywordExtractor()\n",
    "    global keywords\n",
    "    keywords = keyword_extractor.extract_keywords(data)\n",
    "    keyword_list = []\n",
    "    for kw in keywords:\n",
    "        keyword_list.append(kw[0])\n",
    "    return keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7204e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'].apply(yake_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all keywords \n",
    "all_keywords = []\n",
    "for kw in keywords :\n",
    "    all_keywords.append(kw)\n",
    "print(all_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffcfd2d",
   "metadata": {},
   "source": [
    "## Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_extractor(data):\n",
    "    keyword_extractor = Rake()\n",
    "    keyword_extractor.extract_keywords_from_text(data)\n",
    "    return keyword_extractor.get_ranked_phrases()\n",
    "\n",
    "df['Review'].apply(rake_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e162b6e",
   "metadata": {},
   "source": [
    "## Unlabelled Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# 1.remove spaces,newlines\n",
    "def remove_spaces(data):\n",
    "    clean_text = data.replace('\\\\n',' ').replace('\\t',' ').replace('\\\\',' ')\n",
    "    return clean_text\n",
    "\n",
    "# 2.contraction mapping\n",
    "def expand_text(data):\n",
    "    expanded_text = contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "# 3.Handling accented characters\n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "# 4.Cleaning\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('nor')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "# autocorrection\n",
    "def autocorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text = spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "# lemmatization\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data=[]\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "    return ' '.join(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1626f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train = df['Review'].apply(remove_spaces)\n",
    "clean_text_train = clean_text_train.apply(expand_text)\n",
    "clean_text_train = clean_text_train.apply(handling_accented)\n",
    "clean_text_train = clean_text_train.apply(clean_data)\n",
    "#clean_text_train = clean_text_train.apply(autocorrection)\n",
    "clean_text_train = clean_text_train.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_text_train = clean_text_train.apply(autocorrection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d5a4d",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ae077",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv = CountVectorizer()\n",
    "bow = cnv.fit_transform(clean_text_train)\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv_df = pd.DataFrame(bow.A,columns = cnv.get_feature_names_out())\n",
    "cnv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf1= tfidf.fit_transform(clean_text_train)\n",
    "tfidf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf1.A,columns = tfidf.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3499075",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(df['clean_data'].tolist(),min_count = 2,window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b25fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(list_of_docs,model):\n",
    "    feature = []\n",
    "    for rew in list_of_docs :\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for word in rew :\n",
    "            try :\n",
    "                word in model.wv \n",
    "                vectors.append(model.wv[word])\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if vectors :\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis = 0)\n",
    "            feature.append(avg_vec)\n",
    "        else :\n",
    "            feature.append(zero_vector)\n",
    "            \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cf972",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_docs = vectorizer(df['clean_data'].tolist(),word2vec)\n",
    "vectorized_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ded80",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vectorized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fdaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb = np.array(vectorized_docs)\n",
    "x_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315032a4",
   "metadata": {},
   "source": [
    "## Build Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18241e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_build(cluster,data):\n",
    "    km = KMeans(n_clusters = cluster)\n",
    "    y_pred = km.fit_predict(data)\n",
    "    return km,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word2Vec Clusters\n",
    "model,w2v_cluster = kmeans_build(2,x_emb)\n",
    "w2v_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Countvectorizer\n",
    "\n",
    "model2,bow_cluster = kmeans_build(2,bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfidf model clusters\n",
    "\n",
    "model3,tfidf_cluster = kmeans_build(2,tfidf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1309e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_data_text'] = df['clean_data'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24678855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_data_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe962c02",
   "metadata": {},
   "source": [
    "## Silhoutte score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.metrics import silhouette_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3396e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cluster of Word2Vec = {silhouette_score(vectorized_docs,w2v_cluster)}\")\n",
    "print(f\"Cluster of countvectorizer = {silhouette_score(bow,bow_cluster)}\")\n",
    "print(f\"Cluster of Word2Vec = {silhouette_score(tfidf1,tfidf_cluster)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11e9c1",
   "metadata": {},
   "source": [
    "## silhouette_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30784210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizer(model,data):\n",
    "    visualize =SilhouetteVisualizer(model,colors='yellowbrick')\n",
    "    visualize.fit(data)\n",
    "    visualize.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bow\n",
    "visualizer(model2,bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfidf\n",
    "\n",
    "visualizer(model3,tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f426e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word2Vec\n",
    "\n",
    "visualizer(model,x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96964e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(vectorized_docs).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9182a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(np.array(vectorized_docs).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w2v_cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd91a9",
   "metadata": {},
   "source": [
    "## TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a779f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,stratify = y,test_size = 0.3,random_state = 15 )\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafd4d2",
   "metadata": {},
   "source": [
    "## BernaulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc27907",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(x,y,model):\n",
    "    y_pred = model.predict(x)\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(F\"confusion matrix = \\n{cm}\")\n",
    "    print('*'*30)\n",
    "    \n",
    "    acc = accuracy_score(y,y_pred)\n",
    "    print(f\"Accuracy Score = {acc}\")\n",
    "    print('*'*30)\n",
    "    \n",
    "    recall = recall_score(y,y_pred,average='micro')\n",
    "    print(F\"Recall Score = {recall}\")\n",
    "    print('*'*30)\n",
    "    \n",
    "    precision = precision_score(y,y_pred,average='weighted')\n",
    "    print(f\"Precision Score = {precision}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6aa7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ea058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5ef56",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a31ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54664f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a169f88",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "173c55f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cf987ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[  0 167]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 0.7614285714285715\n",
      "******************************\n",
      "Recall Score = 0.7614285714285715\n",
      "******************************\n",
      "Precision Score = 0.5797734693877551\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f3bf32e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[  0  72]\n",
      " [  0 228]]\n",
      "******************************\n",
      "Accuracy Score = 0.76\n",
      "******************************\n",
      "Recall Score = 0.76\n",
      "******************************\n",
      "Precision Score = 0.5776\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07400870",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d783e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "54f22a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train_df = scaler.fit_transform(x_train)\n",
    "x_test_df = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "235c4cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c33c79d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[137  30]\n",
      " [  4 529]]\n",
      "******************************\n",
      "Accuracy Score = 0.9514285714285714\n",
      "******************************\n",
      "Recall Score = 0.9514285714285714\n",
      "******************************\n",
      "Precision Score = 0.9523682288353242\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train_df,y_train,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d924415e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a040877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 100)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4a162541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 46  26]\n",
      " [  6 222]]\n",
      "******************************\n",
      "Accuracy Score = 0.8933333333333333\n",
      "******************************\n",
      "Recall Score = 0.8933333333333333\n",
      "******************************\n",
      "Precision Score = 0.8926302729528537\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test_df,y_test,knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef826a",
   "metadata": {},
   "source": [
    "## Hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "52fe7488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'n_neighbors': array([ 3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        'p': [1, 2]})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1 = KNeighborsClassifier()\n",
    "hyp = {'n_neighbors':np.arange(3,20,2),'p':[1,2]}\n",
    "rscv = RandomizedSearchCV(knn1,hyp)\n",
    "rscv.fit(x_train_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f779416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3f7fd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1 = rscv.best_estimator_\n",
    "knn1.fit(x_train_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6e0fb61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[130  37]\n",
      " [  3 530]]\n",
      "******************************\n",
      "Accuracy Score = 0.9428571428571428\n",
      "******************************\n",
      "Recall Score = 0.9428571428571428\n",
      "******************************\n",
      "Precision Score = 0.9449311108458978\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train_df,y_train,knn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "76f77cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 46  26]\n",
      " [  3 225]]\n",
      "******************************\n",
      "Accuracy Score = 0.9033333333333333\n",
      "******************************\n",
      "Recall Score = 0.9033333333333333\n",
      "******************************\n",
      "Precision Score = 0.906581022847386\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test_df,y_test,knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb881d59",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b0c6f3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=15)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 15)\n",
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9734261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[167   0]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 1.0\n",
      "******************************\n",
      "Recall Score = 1.0\n",
      "******************************\n",
      "Precision Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "## tarining\n",
    "\n",
    "model_eval(x_train,y_train,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d37b7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 53  19]\n",
      " [ 22 206]]\n",
      "******************************\n",
      "Accuracy Score = 0.8633333333333333\n",
      "******************************\n",
      "Recall Score = 0.8633333333333333\n",
      "******************************\n",
      "Precision Score = 0.8654222222222222\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca92ed",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "62c6b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=15),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([3, 4, 5, 6, 7]),\n",
       "                                        'min_samples_leaf': array([3, 4, 5, 6, 7]),\n",
       "                                        'min_samples_split': array([3, 4, 5, 6, 7])})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(random_state = 15)\n",
    "hyp = {'criterion':['gini','entropy'],\n",
    "      'max_depth':np.arange(3,8),\n",
    "      'min_samples_leaf':np.arange(3,8),\n",
    "      'min_samples_split':np.arange(3,8)}\n",
    "rscv = RandomizedSearchCV(dt1,hyp)\n",
    "rscv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d908c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=6,\n",
       "                       min_samples_split=7, random_state=15)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3e3df466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=6,\n",
       "                       min_samples_split=7, random_state=15)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 = rscv.best_estimator_\n",
    "dt1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5d98b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[138  29]\n",
      " [  9 524]]\n",
      "******************************\n",
      "Accuracy Score = 0.9457142857142857\n",
      "******************************\n",
      "Recall Score = 0.9457142857142857\n",
      "******************************\n",
      "Precision Score = 0.9454633354245857\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ee9e886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 38  34]\n",
      " [ 17 211]]\n",
      "******************************\n",
      "Accuracy Score = 0.83\n",
      "******************************\n",
      "Recall Score = 0.83\n",
      "******************************\n",
      "Precision Score = 0.8203487940630797\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11bc78",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d0694641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=15)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 15)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5e2ca330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[167   0]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 1.0\n",
      "******************************\n",
      "Recall Score = 1.0\n",
      "******************************\n",
      "Precision Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f3339068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 50  22]\n",
      " [  2 226]]\n",
      "******************************\n",
      "Accuracy Score = 0.92\n",
      "******************************\n",
      "Recall Score = 0.92\n",
      "******************************\n",
      "Precision Score = 0.9233498759305212\n"
     ]
    }
   ],
   "source": [
    "## testing\n",
    "\n",
    "model_eval(x_test,y_test,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00fdaaa",
   "metadata": {},
   "source": [
    "## Hyperparaeter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b0773bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(random_state=15),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([3, 4, 5, 6, 7]),\n",
       "                                        'min_samples_leaf': array([3, 4, 5, 6, 7]),\n",
       "                                        'min_samples_split': array([3, 4, 5, 6, 7]),\n",
       "                                        'n_estimators': array([ 50,  60,  70,  80,  90, 100])})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(random_state = 15)\n",
    "hyp = {'criterion':['gini','entropy'],\n",
    "      'n_estimators':np.arange(50,110,10),\n",
    "      'max_depth':np.arange(3,8),\n",
    "      'min_samples_split':np.arange(3,8),\n",
    "      'min_samples_leaf':np.arange(3,8)}\n",
    "rscv = RandomizedSearchCV(rf1,hyp)\n",
    "rscv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "495ae1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, min_samples_leaf=4,\n",
       "                       min_samples_split=7, n_estimators=80, random_state=15)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "33279961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, min_samples_leaf=4,\n",
       "                       min_samples_split=7, n_estimators=80, random_state=15)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = rscv.best_estimator_\n",
    "rf2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "738095f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[167   0]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 1.0\n",
      "******************************\n",
      "Recall Score = 1.0\n",
      "******************************\n",
      "Precision Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "01059436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 52  20]\n",
      " [  0 228]]\n",
      "******************************\n",
      "Accuracy Score = 0.9333333333333333\n",
      "******************************\n",
      "Recall Score = 0.9333333333333333\n",
      "******************************\n",
      "Precision Score = 0.9387096774193548\n"
     ]
    }
   ],
   "source": [
    "model_eval(x_test,y_test,rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96e8f0",
   "metadata": {},
   "source": [
    "## Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8d4f6106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=15)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state = 15)\n",
    "ada.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "03a1bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[167   0]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 1.0\n",
      "******************************\n",
      "Recall Score = 1.0\n",
      "******************************\n",
      "Precision Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7437e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 57  15]\n",
      " [  3 225]]\n",
      "******************************\n",
      "Accuracy Score = 0.94\n",
      "******************************\n",
      "Recall Score = 0.94\n",
      "******************************\n",
      "Precision Score = 0.9404999999999999\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767380b",
   "metadata": {},
   "source": [
    "## Hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "96aefb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=AdaBoostClassifier(random_state=15),\n",
       "                   param_distributions={'learning_rate': array([0.01, 0.11, 0.21, 0.31, 0.41, 0.51, 0.61, 0.71, 0.81, 0.91]),\n",
       "                                        'n_estimators': array([10, 20, 30, 40, 50])})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada1 = AdaBoostClassifier(random_state = 15)\n",
    "hyp = {'n_estimators':np.arange(10,60,10),\n",
    "      'learning_rate':np.arange(0.01,1,0.1)}\n",
    "rscv = RandomizedSearchCV(ada1,hyp)\n",
    "rscv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cda4162e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.6100000000000001, random_state=15)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "de56875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.6100000000000001, random_state=15)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada1 = rscv.best_estimator_\n",
    "ada1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "811e9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[167   0]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 1.0\n",
      "******************************\n",
      "Recall Score = 1.0\n",
      "******************************\n",
      "Precision Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "model_eval(x_train,y_train,ada1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "04573e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 59  13]\n",
      " [  1 227]]\n",
      "******************************\n",
      "Accuracy Score = 0.9533333333333334\n",
      "******************************\n",
      "Recall Score = 0.9533333333333334\n",
      "******************************\n",
      "Precision Score = 0.9548333333333333\n"
     ]
    }
   ],
   "source": [
    "## testing\n",
    "\n",
    "model_eval(x_test,y_test,ada1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ae79c",
   "metadata": {},
   "source": [
    "## SVM = SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "29a3453d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "29603736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[164   3]\n",
      " [  0 533]]\n",
      "******************************\n",
      "Accuracy Score = 0.9957142857142857\n",
      "******************************\n",
      "Recall Score = 0.9957142857142857\n",
      "******************************\n",
      "Precision Score = 0.9957382729211087\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "\n",
    "model_eval(x_train,y_train,svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5bdc534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      "[[ 61  11]\n",
      " [  1 227]]\n",
      "******************************\n",
      "Accuracy Score = 0.96\n",
      "******************************\n",
      "Recall Score = 0.96\n",
      "******************************\n",
      "Precision Score = 0.9610029818378966\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "model_eval(x_test,y_test,svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57bd010",
   "metadata": {},
   "source": [
    "## User defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cd3adcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4ec76dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('restau.model')\n",
    "\n",
    "with open('resau_svm_model.pkl','wb') as file:\n",
    "    pickle.dump(svm,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f8c5f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# 1.remove spaces,newlines\n",
    "def remove_spaces(data):\n",
    "    clean_text = data.replace('\\\\n',' ').replace('\\t',' ').replace('\\\\',' ')\n",
    "    return clean_text\n",
    "\n",
    "# 2.contraction mapping\n",
    "def expand_text(data):\n",
    "    expanded_text = contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "# 3.Handling accented characters\n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "# 4.Cleaning\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('nor')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "# autocorrection\n",
    "def autocorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text = spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "# lemmatization\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data=[]\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "    return ' '.join(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "85cbc67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow... Loved this place.'"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ='Wow... Loved this place.'\n",
    "#data = df['clean_data'][0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "592c7b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow loved place'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = remove_spaces(data)\n",
    "user_data = expand_text(user_data)\n",
    "user_data = handling_accented(user_data)\n",
    "user_data = clean_data(user_data)\n",
    "user_data = autocorrection(' '.join(user_data))\n",
    "user_data = lemmatization(user_data.split())\n",
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "cacc1a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x23eb1f9ed90>"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Word2Vec.load('restau.model',user_data)\n",
    "model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "6f4d4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(list_of_docs,model):\n",
    "    feature = []\n",
    "    for rew in list_of_docs :\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for word in rew :\n",
    "            try :\n",
    "                word in model.wv \n",
    "                vectors.append(model.wv[word])\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if vectors :\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis = 0)\n",
    "            feature.append(avg_vec)\n",
    "        else :\n",
    "            feature.append(zero_vector)\n",
    "            \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "d18ed2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wow', 'loved', 'place']]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = pd.Series([user_data.split()])\n",
    "user.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "002b065a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00237288,  0.0081949 , -0.00066017,  0.00478384, -0.0011599 ,\n",
       "        -0.00372177,  0.00072419,  0.00753723,  0.00209678, -0.0083062 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data1 = np.array(vectorizer(user.tolist(),model1))\n",
    "user_data1[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a452af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(user_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f2af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
